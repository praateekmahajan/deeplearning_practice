{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 439,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 440,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data has 3196213 characters, 83 unique.\n"
     ]
    }
   ],
   "source": [
    "data = open('warpeace_input.txt', 'r').read() # should be simple plain text file\n",
    "chars = list(set(data))\n",
    "data_size, vocab_size = len(data), len(chars)\n",
    "print('data has %d characters, %d unique.' % (data_size, vocab_size))\n",
    "char_to_ix = { ch:i for i,ch in enumerate(chars) }\n",
    "ix_to_char = { i:ch for i,ch in enumerate(chars) }\n",
    "\n",
    "class DataReader:\n",
    "    def __init__(self, path, seq_length):\n",
    "        self.fp = open(path, \"r\")\n",
    "        self.data = self.fp.read()\n",
    "        vocab = list(set(self.data))\n",
    "        self.char_to_ix = {ch:i for (i,ch) in enumerate(vocab)}\n",
    "        self.ix_to_char = {i:ch for (i,ch) in enumerate(vocab)}\n",
    "        self.data_size = len(self.data)\n",
    "        self.vocab_size = len(vocab)\n",
    "        self.pointer = 0\n",
    "        self.seq_length = seq_length\n",
    "\n",
    "    def next_batch(self):\n",
    "        input_start = self.pointer\n",
    "        input_end = self.pointer + self.seq_length\n",
    "        inputs = [self.char_to_ix[ch] for ch in self.data[input_start:input_end]]\n",
    "        targets = [self.char_to_ix[ch] for ch in self.data[input_start+1:input_end+1]]\n",
    "        self.pointer += self.seq_length\n",
    "        \n",
    "        # reset pointer\n",
    "        if self.pointer + self.seq_length + 1 >= self.data_size:\n",
    "            input_start = self.pointer\n",
    "            input_end = self.data_size\n",
    "            inputs = [self.char_to_ix[ch] for ch in self.data[input_start:input_end]]\n",
    "            targets = [self.char_to_ix[ch] for ch in self.data[input_start+1:input_end+1]]\n",
    "            self.pointer = self.data_size\n",
    "        return inputs, targets\n",
    "\n",
    "    def just_started(self):\n",
    "        return self.pointer == 0\n",
    "\n",
    "    def epoch_end(self):\n",
    "        return self.pointer == self.data_size\n",
    "\n",
    "    \n",
    "    def close(self):\n",
    "        self.fp.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 446,
   "metadata": {},
   "outputs": [],
   "source": [
    "class F:\n",
    "    def softmax(x):\n",
    "        \"\"\"Compute softmax values for each sets of scores in x.\n",
    "\n",
    "        Subtracts max(x) for numerical stability\n",
    "        Args:\n",
    "            x: an array of size n * 1.\n",
    "        Returns:\n",
    "            A probability distribution over the vector x\n",
    "        \"\"\"\n",
    "        e_x = np.exp(x - np.max(x))\n",
    "        return e_x / e_x.sum()\n",
    "    def crossentropy(pred_prob, target):\n",
    "        return sum(-np.log(pred_prob[t][target[t],0]) for t in range(len(pred_prob.keys())))\n",
    "\n",
    "\n",
    "class RNN:\n",
    "    def __init__(self, num_hidden, num_input):\n",
    "        self.input_size = num_input\n",
    "        self.W_hx = np.random.randn(num_hidden, num_input)*0.01 # input to hidden of dimension hidden * input\n",
    "        self.W_hh = np.random.randn(num_hidden, num_hidden)*0.01 # hidden to hidden of dimension hidden * hidden\n",
    "        self.W_hy = np.random.randn(num_input, num_hidden)*0.01 # hidden to output of dimension input * hidden\n",
    "        \n",
    "        self.b_h = np.zeros((num_hidden, 1)) # hidden bias of dimension hidden * 1\n",
    "        self.b_y = np.zeros((num_input, 1)) # output bias of dimension input * 1\n",
    "\n",
    "        self.h = np.random.randn(num_hidden,1) * 0.01\n",
    "        \n",
    "        # memory vars for adagrad\n",
    "        self.mWxh = np.zeros_like(self.W_hx)\n",
    "        self.mWhh = np.zeros_like(self.W_hh)\n",
    "        self.mWhy = np.zeros_like(self.W_hy)\n",
    "        self.mbh = np.zeros_like(self.b_h)\n",
    "        self.mby = np.zeros_like(self.b_y)\n",
    "\n",
    "        \n",
    "    def step(self, x):\n",
    "        \"\"\"Compute a single step using hidden states for a given x.\n",
    "        Computes three dictionaries x_hat, h, p with keys = timestep\n",
    "        \n",
    "        \n",
    "        Mathematically it is h(t) = tanh((Wh * h(t-1)) + (Wx *x) + bias)\n",
    "                             y = Wy * h + bias\n",
    "        Args:\n",
    "            x: a vector of size n * 1.\n",
    "        Returns:\n",
    "            x_hat: a dictionary of one hot vectors of input for each time step\n",
    "            h: a dictionary of hidden states of each time step\n",
    "            p: Predicted probabilities of each timestep\n",
    "        \"\"\"\n",
    "        h, y_hat, x_hat, p = {}, {}, {}, {}\n",
    "        h[-1] = np.copy(self.h)\n",
    "\n",
    "        for t in range(len(x)):\n",
    "            x_hat[t] = np.zeros((self.input_size,1)) # Convert x into 1-hot-vector\n",
    "            x_hat[t][x[t]] = 1 # Set the index x[t] of 1-hot-vector x_hat[t] to 1\n",
    "            h[t] = np.tanh(np.dot(self.W_hh, h[t-1]) + np.dot(self.W_hx, x_hat[t]) + self.b_h)\n",
    "            y_hat[t] = np.dot(self.W_hy, h[t]) + self.b_y\n",
    "            p[t] = F.softmax(y_hat[t])\n",
    "        return x_hat, h, p\n",
    "    \n",
    "    \n",
    "    def backward(self, x, y, p, h, clip_val=5):\n",
    "        \"\"\"Backpropogates through a sequence\n",
    "\n",
    "        Args:\n",
    "            x: a dictionary of one hot vectors of input for each time step\n",
    "            y: vector containing real output values of dimension n*1\n",
    "            p: a dictionary of predicted probabilities\n",
    "            h: a dictionary of hidden states\n",
    "            clip_val: Clip values of gradient so it doesn't explode\n",
    "        Returns:\n",
    "            dW_hx, dW_hh, dW_hy, db_h, db_y: derivatives of weight vectors and bias\n",
    "        \"\"\"\n",
    "\n",
    "        dW_hx = np.zeros_like(self.W_hx)\n",
    "        dW_hh = np.zeros_like(self.W_hh)\n",
    "        dW_hy = np.zeros_like(self.W_hy)\n",
    "        db_h = np.zeros_like(self.b_h)\n",
    "        db_y = np.zeros_like(self.b_y)\n",
    "        dh_next = np.zeros_like(self.h)\n",
    "\n",
    "        for t in reversed(range(len(x))):\n",
    "            #backprop into y. see http://cs231n.github.io/neural-networks-case-study/#grad if confused here\n",
    "            dy = np.copy(p[t])\n",
    "            dy[y[t]] -= 1\n",
    "\n",
    "            #find updates for y\n",
    "            dW_hy += np.dot(dy, h[t].T)\n",
    "            db_y += dy\n",
    "\n",
    "            #backprop into h and through tanh nonlinearity\n",
    "            dh = np.dot(self.W_hy.T, dy) + dh_next\n",
    "            dh_raw = (1 - h[t]**2) * dh\n",
    "\n",
    "            #find updates for h\n",
    "            dW_hx += np.dot(dh_raw, x[t].T)\n",
    "            dW_hh += np.dot(dh_raw, h[t-1].T)\n",
    "            db_h += dh_raw\n",
    "\n",
    "            #save dh_next for subsequent iteration\n",
    "            dh_next = np.dot(self.W_hh.T, dh_raw)\n",
    "            \n",
    "        # clip to mitigate exploding gradients\n",
    "        for dparam in [dW_hx, dW_hh, dW_hy, db_h, db_y]:\n",
    "            np.clip(dparam, -clip_val, clip_val, out=dparam) \n",
    "        return dW_hx, dW_hh, dW_hy, db_h, db_y\n",
    " \n",
    "    \n",
    "    def sgd(self, dWxh, dWhh, dWhy, dbh, dby, learning_rate=1e-1):\n",
    "        \"\"\"Updates weights with vanilla gradient descent\n",
    "\n",
    "        Args:\n",
    "            dW_hx, dW_hh, dW_hy, db_h, db_y: derivatives of weight vectors and bias\n",
    "            learning_rate: Learning Rate for SGD\n",
    "        \"\"\"\n",
    "        for param, dparam in zip([self.W_hx, self.W_hh, self.W_hy, self.b_h, self.b_y],\n",
    "                                  [dWxh, dWhh, dWhy, dbh, dby]):\n",
    "            param += -learning_rate * dparam\n",
    "\n",
    "    def adagrad(self, dWxh, dWhh, dWhy, dbh, dby, learning_rate=1e-1):\n",
    "        \"\"\"Updates weights with adagrad\n",
    "\n",
    "        Args:\n",
    "            dW_hx, dW_hh, dW_hy, db_h, db_y: derivatives of weight vectors and bias\n",
    "            learning_rate: Learning Rate for Adagrad\n",
    "        \"\"\"\n",
    "        # parameter update with adagrad\n",
    "        for param, dparam, mem in zip([self.W_hx, self.W_hh, self.W_hy, self.b_h, self.b_y],\n",
    "                                  [dWxh, dWhh, dWhy, dbh, dby],\n",
    "                                  [self.mWxh, self.mWhh, self.mWhy, self.mbh, self.mby]):\n",
    "            mem += dparam*dparam\n",
    "            param += -learning_rate*dparam/np.sqrt(mem+1e-8) # adagrad update\n",
    "\n",
    "    def train(self, x, y, optimizer=\"sgd\", lr = 1e-3):\n",
    "        \"\"\"The train function which does the following computation in order\n",
    "            1. Calls step(x) i.e traverses through one sequence\n",
    "            2. Gets loss of predicted values from previous step\n",
    "            3. Computes gradients using backward()\n",
    "            4. Updates weight vectors using our choice of optimizer\n",
    "            5. Sets the hidden state to last hidden state\n",
    "\n",
    "        Args:\n",
    "            dW_hx, dW_hh, dW_hy, db_h, db_y: derivatives of weight vectors and bias\n",
    "            optimizer: sgd or adagrad\n",
    "            lr: Learning Rate for SGD\n",
    "        \n",
    "        Returns:\n",
    "            curr_loss: Cross Entropy loss of our step(x)\n",
    "        \"\"\"\n",
    "        loss = 0\n",
    "        x_one_hot, hidden_states, pred_prob = self.step(x)\n",
    "        curr_loss = F.crossentropy(pred_prob, y)\n",
    "        dW_hx, dW_hh, dW_hy, db_h, db_y = self.backward(x_one_hot, y, pred_prob, hidden_states)\n",
    "        if optimizer == \"sgd\":\n",
    "            self.sgd(dW_hx, dW_hh, dW_hy, db_h, db_y, learning_rate=lr)\n",
    "        elif optimizer == \"adagrad\":\n",
    "            self.adagrad(dW_hx, dW_hh, dW_hy, db_h, db_y, learning_rate=lr)\n",
    "            \n",
    "        self.h = hidden_states[len(pred_prob)-1]\n",
    "        return curr_loss\n",
    "\n",
    "    \n",
    "    \n",
    "    def forward(self, seed, n):\n",
    "        \"\"\" \n",
    "        Do one forward pass, with the starting character as seed\n",
    "        h is memory state, seed is seed letter for first time step\n",
    "        \n",
    "        Args:\n",
    "            seed: index of first character for time step\n",
    "            n : size of sequence (time steps)\n",
    "        Returns:\n",
    "            predicted_index: a vector of size n with predicted_indexes for timestep t + 1\n",
    "        \"\"\"\n",
    "        \n",
    "        x = np.zeros((self.input_size, 1))\n",
    "        x[seed] = 1\n",
    "        predicted_indexes = []\n",
    "        for t in range(n):\n",
    "            h = np.copy(self.h)\n",
    "            h = np.tanh(np.dot(self.W_hh, h) + np.dot(self.W_hx, x) + self.b_h)\n",
    "            y = np.dot(self.W_hy, h) + self.b_y\n",
    "            p = F.softmax(y)\n",
    "            predicted_char = np.random.choice(range(self.input_size), p=p.ravel())\n",
    "            x = np.zeros((self.input_size, 1))\n",
    "            x[predicted_char] = 1\n",
    "            predicted_indexes.append(predicted_char)\n",
    "        return predicted_indexes\n",
    "\n",
    "    def show_weight(self):\n",
    "        print(self.h)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 443,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 1000 89.87140817751805\n",
      "pvfigasmge grdrggooaieiggiioedtagteaege ae i nhisepi Os w lnndggtpr t\n",
      "g\n",
      "linmdLorprn aie oiyriean.ona\n",
      "0 2000 76.70681295072802\n",
      " uw ahiodsgc\n",
      "\n",
      "rptytfietpyVnrwahsee\n",
      "e.wwtn nidibt4ftn e et  lbe h\n",
      "a e 5h iwu iiielZgiiwcpinoor c5 nee\n",
      "0 3000 71.74424495895674\n",
      " dMn )tfgndd \n",
      "eeoep  furedo Perddnp  tfi\n",
      "\n",
      "\n",
      "w v.ap5 ieiwea feiehfai p  hinrvaln ip\n",
      "dgfea\n",
      " t rr\n",
      "w i ep\n",
      "0 4000 69.92532956044005\n",
      "d u fmoipiiPohtr iandmerekie .nftdv ityr e vdndndeitigvgrfhn w nrba fprp h nwn  hn od  s\n",
      "ncwdofr i\n",
      " \n",
      "0 5000 67.49850122170976\n",
      "n lggeo ndd d r r nuemHoul giiigd iw u s mv\n",
      "din erioiinilaeieiinyd le ma r p ro reyilae n Holw eveir\n",
      "0 6000 61.79237461239441\n",
      "\n",
      "heee e y riyiivav \n",
      "n hiredd h vee vipoygia' n gin n ae re vmiind r n win h\n",
      "geies n wrile pbogroe l \n",
      "0 7000 56.39705356849012\n",
      "voowaoh nI ae neIilede\n",
      "\n",
      "isoaeisiniirel non eé , aled sd rgcr\n",
      "hs rn p,mad te aagos\n",
      " 1wWin hnaiuisoira\n",
      "0 8000 47.53118849012008\n",
      ",edehiin\n",
      "iarrdinecbogrv\n",
      "hhiforgililiri\n",
      "iritnrner ileiseSsen iwin whiwiininethoeaglr\n",
      "auneginr\n",
      "toani\n",
      "l\n",
      "0 9000 39.45572781416384\n",
      "endd rire un wih sipongime ors rWey \n",
      "a nedir sfild ot ne m lineyh trd pu tefearrqfkeiarirose ndeerd \n",
      "0 10000 34.51640107303447\n",
      "n tunddore.rrlepirr,eyhnetehilir ,erf, lcndiWaginddtyawind vginderrêlis.iawhhhd terd piwind ws wingw\n",
      "0 11000 31.334637072417582\n",
      "indindin wilinelrsotiluon Hirene\n",
      " or\n",
      "hilolesircsineddhilindicotinene wiloro﻿eeuswirgauIamleol, bolon\n",
      "0 12000 28.991066618874726\n",
      "s p nd ob \n",
      "r\n",
      "totd p s tets ays pgir \n",
      "tt tsd pelgingint vit t o,e rd ole5e hgop hend pine pcor s pin \n",
      "0 13000 26.965821309974576\n",
      "rin ssindincte \n",
      "waciroranetewoltresineshuheed wiriron.aon behe \n",
      "vilildopiles\n",
      "\n",
      "onD abdilee ? orehorar\n",
      "0 14000 24.92543155378709\n",
      ".h \"hesh leresa f! \n",
      "usld fn fwiwheedeginri\"0 s fiwind fh ogile,edelbee ri\" leh\n",
      "rhd t wiwiwike ugaret\n",
      "0 15000 22.939188910431717\n",
      "dintcopishindikind a\n",
      "\n",
      "wejacriniloririn \n",
      "in it hiner\n",
      "\n",
      "apind Hherin avin had ai\n",
      "winedyilene, ourerildy\n",
      "0 16000 20.791961908695367\n",
      " pald wiwCge wis wi\n",
      "winde tgiwire yd p mel p w wouese wed pxG w. piwhd wingiwotee à He wist pe/gim d\n",
      "0 17000 17.873171106922456\n",
      "ocemginda\n",
      "id s ot wir!uad retde ofscedaledt.ela, oas weU o atunedee wil s r po ne tce a nm'cs tdh an\n",
      "0 18000 13.74621492269517\n",
      "re c(d osirhk isshh eah are re hof aaamM ths agand hetayins otoronere c\n",
      "ure pog, at ind \n",
      "hergicok \n",
      "t\n",
      "0 19000 10.011050857584538\n",
      "at\n",
      "hongiswa,tf ok, wetyehew ns tceheelnechosd olom ohedeayt ah .ta w y thd ath ndiceeg. cumeomcos l \n",
      "0 20000 7.241806399729311\n",
      " oln pere terompe arer, f hekhegennd rendyas tmilm mte-. of mod fetrefale, sfgxbd ttat orhgeneifanor\n",
      "0 21000 5.531945394319023\n",
      "ucos aherendeyhotith. ti\"arindeyororearisadisindindiondin\n",
      "wifona\n",
      "\n",
      "hiniuwilasitamindinerauloth tariri\n",
      "0 22000 4.4767199076229485\n",
      "is\n",
      "oand,ro\n",
      "winm \n",
      "uup feladeinde h o eyinetod hhesee teti\n",
      "winld t,ielekold\"borysoAcondan, reril.e han\n",
      "0 23000 3.712774987051728\n",
      "dend \n",
      "cilthetorky\"!oxndendg letondogindonndafindridhiremoperere\n",
      "handand,tatanyalo olunimogile,helthe\n",
      "0 24000 3.145160933503151\n",
      "q thid t b ld\"pind tsattot tmoktatad t was t,e ts fan ashinasitd raK \"tal k ctand wt t o\n",
      "hemerieuust\n",
      "0 25000 2.843124624361231\n",
      "y t agersauut ates rd s fHau\" d \n",
      "f andeang p!hetanyeas windll n\n",
      "r s wcert, t\n",
      "w,or m a, arore\" leinde\n",
      "0 26000 2.6098689081893767\n",
      "n tered T ady the taet nd t pe oly ted okme,ndecaag adualyd vegif gid nddille se sim-t he atesm as n\n",
      "0 27000 2.39669446145518\n",
      "eyLginegt aytocah t nd od.h\n",
      "h gsed olan, sgyd n o trgh s oum t. wlupe\n",
      "utkaenolromsnlt,. \"rOtbow mamT\n",
      "0 28000 2.374798486959481\n",
      "wallotunliss fette. kinn notgeoke stosttmhelert fyel bed'hend on w.ee sutitacanefgsahersth temet uos\n",
      "0 29000 2.283789390787082\n",
      "ousind, u und winiopirer.avilit wanind orif fy oth\n",
      "rered a icig hore arofuo ose rHeare a\n",
      "wime olo he\n",
      "0 30000 2.326661090352304\n",
      "efitisef unde\n",
      "we\n",
      "\n",
      "ho oRasanide\n",
      "he thasa\n",
      "hginobesortudice\n",
      "rteretomesindause ho/elathedanendilemebmos.\n",
      "0 31000 2.204257564256661\n",
      "nd orgas hed uf s b meind  lly windt ti  t he\n",
      "cew ytubbg abiny nd t tistI andifot nd awad - I sivota\n",
      "0 32000 2.1728315700649987\n",
      "s tes, asolelhudcw tav, o es nd oszan sino?fevomofhemaTsiveWy hatamxry \n",
      "weml'kgugh nd n a\"bed waamh\n",
      "\n",
      "0 33000 2.0714576055655716\n",
      " d teslb ind aloyeltennandjisy,e, fed t t tol heme t athindbe\n",
      " be\n",
      "hi feceleFis f af Bemyid.sefaI bes\n",
      "0 34000 2.045539252554987\n",
      "arthed hy facexre aromis!iav., hpr vild wocrid wima hevirou halteseris as hes, a\n",
      "\n",
      "oreerith \n",
      "u e ay a\n",
      "0 35000 2.0259675554359924\n",
      "-iOtelicytodtetWeisceund F\n",
      "\n",
      "a's veld'yil s cilosandR.y idand lin\n",
      "ond all andloukcoates \" wecel sthin\n",
      "0 36000 1.9359856811102063\n",
      " om.rendium Be,uortheceytere taras nd o rgoretikiCsotves, and ou vhevulld pand ofiny p1edio ug b, t \n",
      "0 37000 1.9223966962796124\n",
      "am sortoveser thitethi\" nd kab lteth wrad m\n",
      "Hve fd ny nigerer crd toryd sessrw\n",
      "ap stpeath!fand w t f\n",
      "0 38000 1.9150036542609667\n",
      "d Ho ored oliun u-d slGind pimid ade.iBe adttirey kolimi ce\n",
      "n ,d a f and and ,ui pareitte, m a\n",
      "andd \n",
      "0 39000 1.7878903584839543\n",
      "aweunmundind asrsiy t De btmufs t weu un tetirkeg howt meletlrter nd wGf tend f ns a t nd len aum b8\n",
      "0 40000 1.8776100732265628\n",
      "on5homosor\"vetpifranime bekh he houromodithifochende\n",
      "h Tof't!temisbayolo ade habs-hebndy\n",
      "henrons\n",
      "thg\n",
      "0 41000 1.9498874504992132\n",
      "uwhandetalPilothut\"hinichotitakondindelgimindendalaseunindeRewifoseofarhad ande\n",
      "\n",
      "heou heshenda\n",
      "hofis\n",
      "0 42000 1.8266048067072138\n",
      " l t t w orio r P  cred rh s, h, ley o at, pend srd hile   t winis\" P s nd f c t b, tend nd t w p ra\n",
      "0 43000 1.9625789879878826\n",
      "s nd t' t h coe ceptMe p, m te, tivarhey s\"f lanesj om w sus. og m hes tmat sn we Teed th wefigit\"m.\n",
      "0 44000 1.845896464078966\n",
      " tum t h rd nes t l any as ud 0enrtucerek hy botopend and s p toer parteleerend h wru\" no-and fedt e\n",
      "0 45000 2.0135257928693666\n",
      "ost y t bs s.rertutiticg Siasind \" s ad war sorhos ita, te sirerxh atN\n",
      "adr.reile hesercd y mindbn mr\n",
      "0 46000 1.8783937307581842\n",
      " m rd ind rate tid oets \n",
      "\n",
      "anp, bd, yu ls ef h\n",
      "l cwith\" \n",
      "ursip. t\" usmilg uve l ;eenld, nd fegpaf ad \n",
      "0 47000 1.7757782150252006\n",
      "o p alrerey yg\n",
      "\n",
      "id t s ol. y rls'tut t u f nd o p t frtiund te, ad re tigr es \n",
      "r s Od h metof vancg \n",
      "0 48000 1.7516800159322243\n",
      "iprames\"t s tinp tmlt f nat ts y sed ptte tutomh peushss afinl t m tokte t nd resw mencetrtgg med mh\n",
      "0 49000 1.7434863371568456\n",
      "ve\n",
      "ufithandemofithel\n",
      "ofvindesnly alitan hifaHelondromesarhetherifetheothrokoteculacand tomthemafabel\n",
      "0 50000 1.7771809052258811\n",
      "cala wohincandewin sohowalephoratind handesoletuleurondeondemomosehouul\"sosal,ehondedhi9elandesoho P\n",
      "0 51000 1.6601856627864773\n",
      "eth nd nd tanu u As. as lyy f ä nd bend W be hu nd and ed cend blogife w y he\" re \n",
      "b iond hos bd het\n",
      "0 52000 1.6510575483089807\n",
      "indtha\n",
      "al' andhe hl\"hoderoghhass.iIvifando aleathewandad alnicosof r,ros falen o ohendenillad wholer\n",
      "0 53000 1.6711104848355696\n",
      " ve ts ateteked s s s heme t tvhan t, alsroszor t it bd rke andpd, cu nd mhed r\n",
      "A ndriekgee ohe'ns i\n",
      "0 54000 1.604331464847335\n",
      "wmlrtohed\n",
      "h, hed tes\n",
      "hoshHsacatrthemonca\n",
      "wisraland.kgewicratp, w'wlatass,.sch?sun ad se w\n",
      "rmkokesmhe\n",
      "0 55000 1.5714086251644532\n",
      "mesuthonroserhethaucherheshoe\n",
      "wororhoverh.hethinx'Hesuhemilomuotoundansanyaundilchevemerorithe hherh\n",
      "0 56000 1.528914984570328\n",
      " ad od.rs u f b resi or ?u oc, wansrarti wis.\n",
      "u t vir an o otey oun wa\n",
      "adend hinrub f. allond nd cae\n",
      "0 57000 1.5073683631909573\n",
      "orond ath\n",
      "humi owre os\n",
      "\" nd hurt!ere hore toroutuy alu ars itasa hertole o I asindpie achetend as ad\n",
      "0 58000 1.5693919217854118\n",
      "enista Nivg! to onde o f tat tend she hi nd, ikeind w arld \" oscowa\n",
      "t arorond h s whe t and al t'nd \n",
      "0 59000 1.6772820960790729\n",
      "lengistovinlsouel\"tayondefrandela\n",
      "Mhegorssundachawindeoro)ounlandetofpton anghohe womoeche tafind th\n",
      "0 60000 1.5908582790032884\n",
      "ery avicivedherendeedawis brtarouk horausWohimidet.indaroreturkoumid in\n",
      "havere!ohatece ir a,etese is\n",
      "0 61000 1.595184137406636\n",
      "w.\n",
      "u kmind s!end hFtdilay le och tolecherondiminc\" b ind berolsSand hero at!.\n",
      "fescad ment; ad cedile\n",
      "0 62000 1.568030498971695\n",
      " T s a ras mn reYises v p m t Nnd h t f sheend w w f siAneslut noh t w d \"pit t nd ubect and w but n\n",
      "0 63000 1.516463353380629\n",
      "tu sle, w med vim ta ad b as M\n",
      "w\"h tke,, t for ond. hougew ule qs P meand a'p, aresand rcc be\n",
      "Mond c\n",
      "0 64000 1.5750064123790801\n",
      " wa w yeheukrhep ule bu H qreweamanmrMerm, wen m tot w t; seFp!t rsf r rs sreslend hep velossv w:h b\n",
      "0 65000 1.60255193243592\n",
      "erleetemth Deteny I! ben wvehe -cuel L,land shtim ooc p osmsevetite! ageupald asefound moes,ind aule\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 66000 1.6644847828401352\n",
      "v osremt m t tud Ipend cr t t\n",
      "hee af ng tp\n",
      "hend rin d rt,, newreily b wif mm gund I berf sus, nd f t\n",
      "0 67000 1.5584471940913975\n",
      "giny(atherondanyindina8inywirendawofoPhebwifashacoshenefokvehinduminomaneyefelerhefocertrosyhilolsan\n",
      "0 68000 1.6432327836407679\n",
      "Ala, PHeos ha cere\n",
      "a t mets P y,.ts rorls t copescond thorexeeh a feeliery Ed hes ind h,\n",
      "wh s, ltena\n",
      "0 69000 1.6255535373506866\n",
      " osim K t tand h w ind f wind peg wi!r h mikee p\n",
      "h, tehet p amicatve ah he h tee w te re hereis oh, \n",
      "0 70000 1.5160533608718656\n",
      " Hijend wsi ante-rekoNeers heéshendsa hete wind windelen retamaf he wind msele\n",
      "Ri\n",
      "\n",
      "iconde.\n",
      "ase worev\n",
      "0 71000 1.453608271694812\n",
      "lt, Ej m.kls td t I pmis, ndevird Mevol t nt l jtattrr resrose tl n?und st wesm to opetu-t p we atrs\n",
      "0 72000 1.523037241206812\n",
      "ltiupete tow, ty t nd p al y h f hireud het tin cif as wimtit. f h ry orneves rg nd tTh yry 5, ud b \n",
      "0 73000 1.4773552534400696\n",
      "ontandamathandhindendendeuutuflilathindhetosond th,motalwonduleomind.\n",
      "isyherwhondssoundecoh Osh thyr\n",
      "0 74000 1.7196286239326721\n",
      " s nd o tind w\n",
      "nd he oo-we ?. m t ch wicumiche\n",
      "vi aflir watrli i t t imidic teaejecete ad.\n",
      "fth tatek\n",
      "0 75000 1.5986562408890348\n",
      "are ilondundapindendel \". pogthorond \"roovesedendemoroniRonderorede w?iretarewitulatoosile P whetilo\n",
      "0 76000 1.733198574257868\n",
      " w Eclt oge he Hey. amga r, ookete'les bei e blo s af, P aVs olg s\n",
      "f s te t tehih sremeered berese o\n",
      "0 77000 1.5384814488076375\n",
      " ondytivele P icu alounditel A tawe orefewinders.\n",
      "\n",
      "erohe ticon a\n",
      "hovyt, andeteDovandecinlerollye ure\n",
      "0 78000 1.4541431861834857\n",
      "in odovinditorysethend avifiladiwher?haitarekoparrouwoll\n",
      "sulerulireecetresyo stifi, andiferecofilend\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-443-ee142aea91fb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcounter\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlosses\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtxt_x\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m         \u001b[0msmooth_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msmooth_loss\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m0.999\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m0.001\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0mlosses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msmooth_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-441-1e7069afb9c2>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, x, y)\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 109\u001b[0;31m         \u001b[0mx_one_hot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred_prob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    110\u001b[0m         \u001b[0mcurr_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcrossentropy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred_prob\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m         \u001b[0mdW_hx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdW_hh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdW_hy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdb_h\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdb_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_one_hot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred_prob\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-441-1e7069afb9c2>\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, x, hprev)\u001b[0m\n\u001b[1;32m     53\u001b[0m             \u001b[0mh\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtanh\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mW_hh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mW_hx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_hat\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mb_h\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m             \u001b[0my_hat\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mW_hy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mb_y\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m             \u001b[0mp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_hat\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mx_hat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-441-1e7069afb9c2>\u001b[0m in \u001b[0;36msoftmax\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m      9\u001b[0m             \u001b[0mA\u001b[0m \u001b[0mprobability\u001b[0m \u001b[0mdistribution\u001b[0m \u001b[0mover\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mvector\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \"\"\"\n\u001b[0;32m---> 11\u001b[0;31m         \u001b[0me_x\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0me_x\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0me_x\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcrossentropy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred_prob\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "sequence_length = 25\n",
    "epochs = 10\n",
    "batches = int(len(data)/sequence_length)\n",
    "rnn = RNN(10, vocab_size)\n",
    "losses = []\n",
    "smooth_loss = -np.log(1.0/vocab_size)*sequence_length\n",
    "losses.append(smooth_loss)\n",
    "data_reader = DataReader(\"warpeace_input.txt\", sequence_length)\n",
    "for epoch in range(epochs):\n",
    "    counter = 0\n",
    "    while(data_reader.epoch_end):\n",
    "        counter += 1\n",
    "        inputs, targets = data_reader.next_batch()\n",
    "        rnn.train(inputs, targets)\n",
    "        if counter%1000 == 999:\n",
    "            pred_x = rnn.forward(inputs[0], 50)\n",
    "            txt_x = ''.join([ix_to_char[n] for n in pred_x])\n",
    "            txt_y = ''.join([ix_to_char[n] for n in y])    \n",
    "            print(epoch, counter+1, losses[-1])\n",
    "            print(txt_x)\n",
    "        loss = rnn.train(x,y)\n",
    "        smooth_loss = smooth_loss*0.999 + loss*0.001\n",
    "        losses.append(smooth_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 444,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYwAAAEKCAYAAAAB0GKPAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fa253ffdd30>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(range(len(losses)), losses, 'b', label='smooth loss')\n",
    "plt.xlabel('time in thousands of iterations')\n",
    "plt.ylabel('loss')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
