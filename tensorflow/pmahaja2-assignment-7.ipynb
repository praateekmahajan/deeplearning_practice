{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ivncaCtSo4W1"
   },
   "source": [
    "# Some Simple TensorFlow Exercises\n",
    "\n",
    "In class, we'll discuss some of the differences between PyTorch and TensorFlow.\n",
    "\n",
    "The examples below will give you exposure to TensorFlow at the simplest level.\n",
    "\n",
    "If you intend to work more with TensorFlow, I recommend these resources:\n",
    "- [Aymeric Damien's Simple Examples](https://github.com/aymericdamien/TensorFlow-Examples). These are very simple examples that are designed to get key concepts across.\n",
    "- [Keras](https://keras.io/). Keras is a high-level library that's built *on top of* TensorFlow (with support for other backends, too). It makes using TensorFlow much easier and much less error-prone. Also, in 2017, TensorFlow officially adopted Keras, so that fork of Keras is now officially supported.\n",
    "- [TensorFlow Eager](https://research.googleblog.com/2017/10/eager-execution-imperative-define-by.html). We'll see that one of the main differences between PyTorch and TensorFlow is that, in PyTorch, computation graphs are formed *on the fly*, as computationed are peformed. In contrast, in TensorFlow, computation graphs are fully defined before they are ever run. The dynamic approach has many advantages (and some disadvantages), which we'll discuss in class. TensorFlow Eager, introduced in late 2017, aims to bring dynamic computation graphs to TensorFlow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "CnETTtmL05gc"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "GqLzZHX51Clx"
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "x = [1,2,3,4]\n",
    "y = [1,2,3,5]\n",
    "z = tf.equal(x,y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "H7SEEDiHywEa"
   },
   "source": [
    "**Add code in the following cell to print `z`.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 34,
     "output_extras": [
      {
       "item_id": 1
      }
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 332,
     "status": "ok",
     "timestamp": 1522617341527,
     "user": {
      "displayName": "",
      "photoUrl": "",
      "userId": ""
     },
     "user_tz": 240
    },
    "id": "vRaQYqR6yr6E",
    "outputId": "271c19f3-dba4-4ccc-b634-f421dd890ca6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Equal:0\", shape=(4,), dtype=bool)\n"
     ]
    }
   ],
   "source": [
    "print(z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zAKGcfOzyeeI"
   },
   "source": [
    "**In the following Markdown Cell, answer: What is the output of the print statement? Why are you seeing \"add\" here?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wpN5z56By2SP"
   },
   "source": [
    "The output shows that z is a tensor. \n",
    "\n",
    "We see add here because z is a sum of x**2 and y. It can be thought of as a function that will be executed once it is run during the session. The \"function\" here is an add operation only."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Fp8imWb72IMn"
   },
   "source": [
    "Let's instantiate a TensorFlow Session, *run* our computation graph, and retrieve the value of `z`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 34,
     "output_extras": [
      {
       "item_id": 1
      }
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 451,
     "status": "ok",
     "timestamp": 1522617659664,
     "user": {
      "displayName": "",
      "photoUrl": "",
      "userId": ""
     },
     "user_tz": 240
    },
    "id": "zuW_BlE-2xOX",
    "outputId": "83b3a349-ef55-4223-8853-b99f234429be"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.75\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as session:\n",
    "   \n",
    "    z_out = session.run(tf.reduce_mean(tf.cast(z, \"float\")))\n",
    "    \n",
    "print(z_out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xNFIQ5QxzaSn"
   },
   "source": [
    "**In the following Markdown Cell, explain each line of code from the previous cell, one sentence per line.** (You don't need to explain the final `print` line; explaining the first 3 lines is enough.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "11WV9OSIzatO"
   },
   "source": [
    "1. We start a tensorflow session.\n",
    "2. We create a dictionary of our inputs to the Tensor z.\n",
    "3. We run our session, which means we run the necessary graph fragment to execute every Operation and evaluate every Tensor in the graph. To the graph we feed in the value z."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QJn_X7caz4wC"
   },
   "source": [
    "**Fill in the following TODOs so that 1) `dz_dx` is an operation that computes $\\frac{dz}{dx}$ and 2) `dz_dx_out` is the value of $\\frac{dz}{dx}$ when $x = 2.0, y = 3.0$.** Hint: Take a look at the documentation for TensorFlow's `gradients` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 34,
     "output_extras": [
      {
       "item_id": 1
      }
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 265,
     "status": "ok",
     "timestamp": 1522618177746,
     "user": {
      "displayName": "",
      "photoUrl": "",
      "userId": ""
     },
     "user_tz": 240
    },
    "id": "mgbDR6Jw1VwO",
    "outputId": "1107db1d-f2d6-4732-ca85-e876d5aa968a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.0\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "x = tf.placeholder('float', name='x')\n",
    "y = tf.placeholder('float', name='y')\n",
    "z = tf.pow(x, 2) + y\n",
    "\n",
    "dz_dx, = tf.gradients(z, x)\n",
    "\n",
    "with tf.Session() as session:\n",
    "    feed_dict = {x: 2.0, y: 3.0}\n",
    "    dz_dx_out = session.run(dz_dx, feed_dict=feed_dict)\n",
    "    \n",
    "print(dz_dx_out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ySwiRnIf0zUf"
   },
   "source": [
    "**Fill in the following TODOs so that both `z` and `dz_dx` are both computed within a single forward, backward pass.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 34,
     "output_extras": [
      {
       "item_id": 1
      }
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 243,
     "status": "ok",
     "timestamp": 1522618313096,
     "user": {
      "displayName": "",
      "photoUrl": "",
      "userId": ""
     },
     "user_tz": 240
    },
    "id": "oaUVGVed1X7Z",
    "outputId": "bdbbc20b-8b8e-4b68-ab70-bea4e21b1c35"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.0 4.0\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "x = tf.placeholder('float', name='x')\n",
    "y = tf.placeholder('float', name='y')\n",
    "z = tf.pow(x, 2) + y\n",
    "\n",
    "dz_dx, =tf.gradients(z, x)\n",
    "\n",
    "with tf.Session() as session:\n",
    "    feed_dict = {x: 2.0, y: 3.0}\n",
    "    z_out, dz_dx_out = session.run([z, dz_dx], feed_dict=feed_dict)\n",
    "    \n",
    "print(z_out, dz_dx_out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nWq3qGSC1JwI"
   },
   "source": [
    "**Fill in the following TODOs in order to carry out linear regression with (full) gradient descent.** Simple google searches like \"TensorFlow l2 loss\" can go a long way. However, *always pay careful attention to the inputs and outputs of the function(s) that you find*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "SRehuvhT1aEz"
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "display_step = 100\n",
    "\n",
    "n_samples = 100\n",
    "m_known = 5\n",
    "b_known = 10\n",
    "x_data = np.linspace(0, 1, n_samples)\n",
    "y_data = m_known*x_data + b_known + 0.1*np.random.randn(n_samples)\n",
    "\n",
    "x = tf.placeholder(tf.float32, name='x')\n",
    "m = tf.Variable(0.0, name='m')\n",
    "b = tf.Variable(0.0, name='b')\n",
    "\n",
    "y_pred = m * x + b\n",
    "\n",
    "y_true = tf.placeholder(tf.float32, name='y_true')\n",
    "\n",
    "loss = tf.nn.l2_loss(y_true - y_pred)\n",
    "\n",
    "optimizer = tf.train.GradientDescentOptimizer(0.0001)\n",
    "train_op = optimizer.minimize(loss)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    for iteration in range(2500):\n",
    "        sess.run(train_op, feed_dict={x: x_data, y_true: y_data})\n",
    "    M = sess.run(m)\n",
    "    B = sess.run(b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8Gq-maHK3gfX"
   },
   "source": [
    "**Write code to print the final values for `m` and `b`.** (If they're not within 1% of `m_known` and `b_known`, then you need to debug.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 34,
     "output_extras": [
      {
       "item_id": 1
      }
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 286,
     "status": "ok",
     "timestamp": 1522619011700,
     "user": {
      "displayName": "",
      "photoUrl": "",
      "userId": ""
     },
     "user_tz": 240
    },
    "id": "xLXbMpJk3h0-",
    "outputId": "d85dc9c1-f35f-4ac6-eb47-0ad08ff269c9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.067363 9.954947\n"
     ]
    }
   ],
   "source": [
    "print(M, B)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Jif9vMSD1dgN"
   },
   "source": [
    "**Modify the code above to create a list of losses, named `losses`, containing the loss value at each iteration (as a float). Below, plot the result, as we have done in previous labs.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "EdI7jcEP31XS"
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "display_step = 100\n",
    "\n",
    "n_samples = 100\n",
    "m_known = 5\n",
    "b_known = 10\n",
    "x_data = np.linspace(0, 1, n_samples)\n",
    "y_data = m_known*x_data + b_known + 0.1*np.random.randn(n_samples)\n",
    "losses = []\n",
    "\n",
    "x = tf.placeholder(tf.float32, name='x')\n",
    "m = tf.Variable(0.0, name='m')\n",
    "b = tf.Variable(0.0, name='b')\n",
    "\n",
    "y_pred = m * x + b\n",
    "\n",
    "y_true = tf.placeholder(tf.float32, name='y_true')\n",
    "\n",
    "loss = tf.nn.l2_loss(y_true - y_pred)\n",
    "\n",
    "optimizer = tf.train.GradientDescentOptimizer(0.0001)\n",
    "train_op = optimizer.minimize(loss)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    for iteration in range(2500):\n",
    "        sess.run(train_op, feed_dict={x: x_data, y_true: y_data})\n",
    "        losses.append((sess.run(loss, feed_dict={x: x_data, y_true: y_data})))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 284,
     "output_extras": [
      {
       "item_id": 1
      },
      {
       "item_id": 2
      }
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 397,
     "status": "ok",
     "timestamp": 1522619322501,
     "user": {
      "displayName": "",
      "photoUrl": "",
      "userId": ""
     },
     "user_tz": 240
    },
    "id": "9Hy635XvLYMM",
    "outputId": "73536370-ed98-407f-bacf-adc48544fe24"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fe6bff55278>]"
      ]
     },
     "execution_count": 28,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD6CAYAAACvZ4z8AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nCnoRkcAp6EVEAvf/ARhJvTvohMQXAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fe6c2beea90>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "bFIkBDjXLuCX"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "default_view": {},
   "name": "cs382-2018-03-27-lab.ipynb",
   "provenance": [
    {
     "file_id": "134HPQbWkbWLnD8Q7tQy-v3v8KKW2ygBY",
     "timestamp": 1522181513358
    }
   ],
   "version": "0.3.2",
   "views": {}
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
